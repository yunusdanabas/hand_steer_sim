{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "igMyGnjE9hEp"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-19 22:50:24.019453: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-03-19 22:50:24.067463: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-03-19 22:50:24.068675: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-03-19 22:50:25.035913: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "RANDOM_SEED = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2HDvhIu9hEr"
      },
      "source": [
        "# Specify each path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NvZP2Zn9hEy"
      },
      "outputs": [],
      "source": [
        "dataset = '/home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/scripts/model/keypoint_classifier/keypoint.csv'\n",
        "model_save_path = '/home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/scripts/model/keypoint_classifier/keypoint_classifier.hdf5'\n",
        "tflite_save_path = '/home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/scripts/model/keypoint_classifier/keypoint_classifier.tflite'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5oMH7x19hEz"
      },
      "source": [
        "# Set number of classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "du4kodXL9hEz"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjnL0uso9hEz"
      },
      "source": [
        "# Dataset reading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QT5ZqtEz9hE0"
      },
      "outputs": [],
      "source": [
        "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2) + 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QmoKFsp49hE0"
      },
      "outputs": [],
      "source": [
        "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xQU7JTZ_9hE0"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxK_lETT9hE0"
      },
      "source": [
        "# Model building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vHBmUf1t9hE1"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input((21 * 2, )),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypqky9tc9hE1",
        "outputId": "5db082bb-30e3-4110-bf63-a1ee777ecd46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dropout (Dropout)           (None, 42)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 20)                860       \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 20)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                210       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1136 (4.44 KB)\n",
            "Trainable params: 1136 (4.44 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MbMjOflQ9hE1"
      },
      "outputs": [],
      "source": [
        "# Model checkpoint callback\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    model_save_path, verbose=1, save_weights_only=False)\n",
        "# Callback for early stopping\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "c3Dac0M_9hE2"
      },
      "outputs": [],
      "source": [
        "# Model compilation\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XI0j1Iu9hE2"
      },
      "source": [
        "# Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WirBl-JE9hE3",
        "outputId": "71b30ca2-8294-4d9d-8aa2-800d90d399de",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            " 1/38 [..............................] - ETA: 21s - loss: 1.8928 - accuracy: 0.1641\n",
            "Epoch 1: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 1s 11ms/step - loss: 1.8051 - accuracy: 0.1945 - val_loss: 1.6485 - val_accuracy: 0.3063\n",
            "Epoch 2/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 1.6586 - accuracy: 0.3281\n",
            "Epoch 2: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.5822 - accuracy: 0.3599 - val_loss: 1.4121 - val_accuracy: 0.4916\n",
            "Epoch 3/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 1.3927 - accuracy: 0.4350\n",
            "Epoch 3: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/yunusdanabas/mambaforge/envs/ros_env/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38/38 [==============================] - 0s 3ms/step - loss: 1.3927 - accuracy: 0.4350 - val_loss: 1.1860 - val_accuracy: 0.5253\n",
            "Epoch 4/1000\n",
            "31/38 [=======================>......] - ETA: 0s - loss: 1.2319 - accuracy: 0.4766\n",
            "Epoch 4: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.2205 - accuracy: 0.4826 - val_loss: 1.0188 - val_accuracy: 0.5365\n",
            "Epoch 5/1000\n",
            "28/38 [=====================>........] - ETA: 0s - loss: 1.1053 - accuracy: 0.5179\n",
            "Epoch 5: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 1.0953 - accuracy: 0.5197 - val_loss: 0.8915 - val_accuracy: 0.5527\n",
            "Epoch 6/1000\n",
            "30/38 [======================>.......] - ETA: 0s - loss: 1.0133 - accuracy: 0.5633\n",
            "Epoch 6: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0068 - accuracy: 0.5692 - val_loss: 0.7869 - val_accuracy: 0.7642\n",
            "Epoch 7/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.9556 - accuracy: 0.5990\n",
            "Epoch 7: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9522 - accuracy: 0.5991 - val_loss: 0.7164 - val_accuracy: 0.7910\n",
            "Epoch 8/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 1.0090 - accuracy: 0.5938\n",
            "Epoch 8: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.9075 - accuracy: 0.6255 - val_loss: 0.6652 - val_accuracy: 0.8122\n",
            "Epoch 9/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.9858 - accuracy: 0.6094\n",
            "Epoch 9: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.8707 - accuracy: 0.6434 - val_loss: 0.6259 - val_accuracy: 0.8266\n",
            "Epoch 10/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.8668 - accuracy: 0.6953\n",
            "Epoch 10: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.8342 - accuracy: 0.6551 - val_loss: 0.5846 - val_accuracy: 0.8353\n",
            "Epoch 11/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.8919 - accuracy: 0.6406\n",
            "Epoch 11: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.8084 - accuracy: 0.6807 - val_loss: 0.5496 - val_accuracy: 0.8534\n",
            "Epoch 12/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.8257 - accuracy: 0.6562\n",
            "Epoch 12: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.7880 - accuracy: 0.6836 - val_loss: 0.5216 - val_accuracy: 0.8790\n",
            "Epoch 13/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.7619 - accuracy: 0.6926\n",
            "Epoch 13: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.7656 - accuracy: 0.6921 - val_loss: 0.4967 - val_accuracy: 0.8827\n",
            "Epoch 14/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.7508 - accuracy: 0.7044\n",
            "Epoch 14: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.7508 - accuracy: 0.7044 - val_loss: 0.4782 - val_accuracy: 0.8902\n",
            "Epoch 15/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.7284 - accuracy: 0.7422\n",
            "Epoch 15: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.7165 - accuracy: 0.7142 - val_loss: 0.4546 - val_accuracy: 0.8983\n",
            "Epoch 16/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.7049 - accuracy: 0.7266\n",
            "Epoch 16: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.7101 - accuracy: 0.7206 - val_loss: 0.4369 - val_accuracy: 0.8952\n",
            "Epoch 17/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.7008 - accuracy: 0.7262\n",
            "Epoch 17: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.7008 - accuracy: 0.7262 - val_loss: 0.4163 - val_accuracy: 0.9070\n",
            "Epoch 18/1000\n",
            "30/38 [======================>.......] - ETA: 0s - loss: 0.6702 - accuracy: 0.7406\n",
            "Epoch 18: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.6763 - accuracy: 0.7391 - val_loss: 0.3955 - val_accuracy: 0.9127\n",
            "Epoch 19/1000\n",
            "30/38 [======================>.......] - ETA: 0s - loss: 0.6623 - accuracy: 0.7461\n",
            "Epoch 19: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.6505 - accuracy: 0.7516 - val_loss: 0.3811 - val_accuracy: 0.9164\n",
            "Epoch 20/1000\n",
            "28/38 [=====================>........] - ETA: 0s - loss: 0.6518 - accuracy: 0.7494\n",
            "Epoch 20: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.6510 - accuracy: 0.7481 - val_loss: 0.3710 - val_accuracy: 0.9083\n",
            "Epoch 21/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.6381 - accuracy: 0.7539\n",
            "Epoch 21: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.6406 - accuracy: 0.7520 - val_loss: 0.3543 - val_accuracy: 0.9164\n",
            "Epoch 22/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.6817 - accuracy: 0.7266\n",
            "Epoch 22: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6450 - accuracy: 0.7518 - val_loss: 0.3549 - val_accuracy: 0.9077\n",
            "Epoch 23/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.5987 - accuracy: 0.7578\n",
            "Epoch 23: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6266 - accuracy: 0.7531 - val_loss: 0.3358 - val_accuracy: 0.9251\n",
            "Epoch 24/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.5348 - accuracy: 0.7656\n",
            "Epoch 24: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6081 - accuracy: 0.7601 - val_loss: 0.3257 - val_accuracy: 0.9226\n",
            "Epoch 25/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.5946 - accuracy: 0.8125\n",
            "Epoch 25: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.6201 - accuracy: 0.7581 - val_loss: 0.3218 - val_accuracy: 0.9245\n",
            "Epoch 26/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.6210 - accuracy: 0.7812\n",
            "Epoch 26: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5898 - accuracy: 0.7745 - val_loss: 0.3063 - val_accuracy: 0.9233\n",
            "Epoch 27/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.5448 - accuracy: 0.7734\n",
            "Epoch 27: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5947 - accuracy: 0.7710 - val_loss: 0.2997 - val_accuracy: 0.9264\n",
            "Epoch 28/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.6280 - accuracy: 0.7578\n",
            "Epoch 28: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.7789 - val_loss: 0.2936 - val_accuracy: 0.9264\n",
            "Epoch 29/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.7284 - accuracy: 0.7109\n",
            "Epoch 29: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5878 - accuracy: 0.7741 - val_loss: 0.2891 - val_accuracy: 0.9264\n",
            "Epoch 30/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.6177 - accuracy: 0.7344\n",
            "Epoch 30: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.7724 - val_loss: 0.2812 - val_accuracy: 0.9339\n",
            "Epoch 31/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.6754 - accuracy: 0.7266\n",
            "Epoch 31: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5862 - accuracy: 0.7776 - val_loss: 0.2759 - val_accuracy: 0.9401\n",
            "Epoch 32/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.5149 - accuracy: 0.7969\n",
            "Epoch 32: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5532 - accuracy: 0.7866 - val_loss: 0.2672 - val_accuracy: 0.9414\n",
            "Epoch 33/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.5202 - accuracy: 0.8281\n",
            "Epoch 33: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.7916 - val_loss: 0.2588 - val_accuracy: 0.9351\n",
            "Epoch 34/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.5248 - accuracy: 0.8047\n",
            "Epoch 34: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.7990 - val_loss: 0.2526 - val_accuracy: 0.9389\n",
            "Epoch 35/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.5644 - accuracy: 0.7812\n",
            "Epoch 35: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.7957 - val_loss: 0.2485 - val_accuracy: 0.9420\n",
            "Epoch 36/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.4367 - accuracy: 0.8125\n",
            "Epoch 36: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.8013 - val_loss: 0.2441 - val_accuracy: 0.9420\n",
            "Epoch 37/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.5027 - accuracy: 0.7891\n",
            "Epoch 37: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.8017 - val_loss: 0.2357 - val_accuracy: 0.9439\n",
            "Epoch 38/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.5601 - accuracy: 0.7734\n",
            "Epoch 38: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.5424 - accuracy: 0.7934 - val_loss: 0.2390 - val_accuracy: 0.9439\n",
            "Epoch 39/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.5243 - accuracy: 0.8075\n",
            "Epoch 39: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.5259 - accuracy: 0.8074 - val_loss: 0.2344 - val_accuracy: 0.9457\n",
            "Epoch 40/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.4427 - accuracy: 0.8203\n",
            "Epoch 40: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.8078 - val_loss: 0.2319 - val_accuracy: 0.9451\n",
            "Epoch 41/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.5422 - accuracy: 0.8359\n",
            "Epoch 41: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.8117 - val_loss: 0.2275 - val_accuracy: 0.9426\n",
            "Epoch 42/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.4492 - accuracy: 0.8438\n",
            "Epoch 42: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.8065 - val_loss: 0.2179 - val_accuracy: 0.9495\n",
            "Epoch 43/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 0.5001 - accuracy: 0.8199\n",
            "Epoch 43: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.8149 - val_loss: 0.2148 - val_accuracy: 0.9501\n",
            "Epoch 44/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.5437 - accuracy: 0.7969\n",
            "Epoch 44: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.8088 - val_loss: 0.2100 - val_accuracy: 0.9520\n",
            "Epoch 45/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.4460 - accuracy: 0.8438\n",
            "Epoch 45: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.8113 - val_loss: 0.2132 - val_accuracy: 0.9507\n",
            "Epoch 46/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.6610 - accuracy: 0.7812\n",
            "Epoch 46: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.8119 - val_loss: 0.2092 - val_accuracy: 0.9501\n",
            "Epoch 47/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.4311 - accuracy: 0.8516\n",
            "Epoch 47: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.8282 - val_loss: 0.2000 - val_accuracy: 0.9520\n",
            "Epoch 48/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.4714 - accuracy: 0.8203\n",
            "Epoch 48: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.8167 - val_loss: 0.1969 - val_accuracy: 0.9588\n",
            "Epoch 49/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.4338 - accuracy: 0.8750\n",
            "Epoch 49: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.4979 - accuracy: 0.8190 - val_loss: 0.1980 - val_accuracy: 0.9557\n",
            "Epoch 50/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.4052 - accuracy: 0.8516\n",
            "Epoch 50: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.8230 - val_loss: 0.1942 - val_accuracy: 0.9526\n",
            "Epoch 51/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.4502 - accuracy: 0.8203\n",
            "Epoch 51: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.8144 - val_loss: 0.1931 - val_accuracy: 0.9532\n",
            "Epoch 52/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.5714 - accuracy: 0.7812\n",
            "Epoch 52: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.8294 - val_loss: 0.1889 - val_accuracy: 0.9532\n",
            "Epoch 53/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.4841 - accuracy: 0.8217\n",
            "Epoch 53: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.8203 - val_loss: 0.1890 - val_accuracy: 0.9526\n",
            "Epoch 54/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.3505 - accuracy: 0.8672\n",
            "Epoch 54: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.8253 - val_loss: 0.1903 - val_accuracy: 0.9507\n",
            "Epoch 55/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.3952 - accuracy: 0.8281\n",
            "Epoch 55: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.8223 - val_loss: 0.1900 - val_accuracy: 0.9545\n",
            "Epoch 56/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.4838 - accuracy: 0.8359\n",
            "Epoch 56: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.8288 - val_loss: 0.1847 - val_accuracy: 0.9545\n",
            "Epoch 57/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.5346 - accuracy: 0.7812\n",
            "Epoch 57: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.8236 - val_loss: 0.1776 - val_accuracy: 0.9607\n",
            "Epoch 58/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.3625 - accuracy: 0.8594\n",
            "Epoch 58: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.8250 - val_loss: 0.1743 - val_accuracy: 0.9588\n",
            "Epoch 59/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.6356 - accuracy: 0.7734\n",
            "Epoch 59: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.8327 - val_loss: 0.1755 - val_accuracy: 0.9551\n",
            "Epoch 60/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.5979 - accuracy: 0.7578\n",
            "Epoch 60: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.8321 - val_loss: 0.1747 - val_accuracy: 0.9532\n",
            "Epoch 61/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.5443 - accuracy: 0.7656\n",
            "Epoch 61: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.8261 - val_loss: 0.1766 - val_accuracy: 0.9563\n",
            "Epoch 62/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.4322 - accuracy: 0.8281\n",
            "Epoch 62: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.8300 - val_loss: 0.1682 - val_accuracy: 0.9607\n",
            "Epoch 63/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.5804 - accuracy: 0.7734\n",
            "Epoch 63: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.8354 - val_loss: 0.1671 - val_accuracy: 0.9601\n",
            "Epoch 64/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.4491 - accuracy: 0.8281\n",
            "Epoch 64: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.8350 - val_loss: 0.1704 - val_accuracy: 0.9613\n",
            "Epoch 65/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.4105 - accuracy: 0.8125\n",
            "Epoch 65: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.8373 - val_loss: 0.1680 - val_accuracy: 0.9613\n",
            "Epoch 66/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.3938 - accuracy: 0.8594\n",
            "Epoch 66: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.8292 - val_loss: 0.1651 - val_accuracy: 0.9613\n",
            "Epoch 67/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.4516 - accuracy: 0.8047\n",
            "Epoch 67: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.8336 - val_loss: 0.1660 - val_accuracy: 0.9619\n",
            "Epoch 68/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.4428 - accuracy: 0.8373\n",
            "Epoch 68: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4500 - accuracy: 0.8357 - val_loss: 0.1684 - val_accuracy: 0.9626\n",
            "Epoch 69/1000\n",
            "26/38 [===================>..........] - ETA: 0s - loss: 0.4363 - accuracy: 0.8347\n",
            "Epoch 69: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.8323 - val_loss: 0.1652 - val_accuracy: 0.9632\n",
            "Epoch 70/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.4508 - accuracy: 0.8268\n",
            "Epoch 70: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.4525 - accuracy: 0.8267 - val_loss: 0.1668 - val_accuracy: 0.9638\n",
            "Epoch 71/1000\n",
            "30/38 [======================>.......] - ETA: 0s - loss: 0.4459 - accuracy: 0.8383\n",
            "Epoch 71: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.4437 - accuracy: 0.8392 - val_loss: 0.1671 - val_accuracy: 0.9613\n",
            "Epoch 72/1000\n",
            "21/38 [===============>..............] - ETA: 0s - loss: 0.4273 - accuracy: 0.8452\n",
            "Epoch 72: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8446 - val_loss: 0.1554 - val_accuracy: 0.9663\n",
            "Epoch 73/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.3085 - accuracy: 0.8672\n",
            "Epoch 73: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.8323 - val_loss: 0.1585 - val_accuracy: 0.9632\n",
            "Epoch 74/1000\n",
            "28/38 [=====================>........] - ETA: 0s - loss: 0.4379 - accuracy: 0.8373\n",
            "Epoch 74: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.8415 - val_loss: 0.1567 - val_accuracy: 0.9651\n",
            "Epoch 75/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.4278 - accuracy: 0.8420\n",
            "Epoch 75: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.8404 - val_loss: 0.1512 - val_accuracy: 0.9669\n",
            "Epoch 76/1000\n",
            "26/38 [===================>..........] - ETA: 0s - loss: 0.4216 - accuracy: 0.8453\n",
            "Epoch 76: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.8434 - val_loss: 0.1510 - val_accuracy: 0.9663\n",
            "Epoch 77/1000\n",
            "26/38 [===================>..........] - ETA: 0s - loss: 0.4377 - accuracy: 0.8380\n",
            "Epoch 77: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.8400 - val_loss: 0.1520 - val_accuracy: 0.9676\n",
            "Epoch 78/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.4247 - accuracy: 0.8411\n",
            "Epoch 78: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.8429 - val_loss: 0.1515 - val_accuracy: 0.9644\n",
            "Epoch 79/1000\n",
            "30/38 [======================>.......] - ETA: 0s - loss: 0.4376 - accuracy: 0.8294\n",
            "Epoch 79: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.8323 - val_loss: 0.1534 - val_accuracy: 0.9638\n",
            "Epoch 80/1000\n",
            "24/38 [=================>............] - ETA: 0s - loss: 0.4138 - accuracy: 0.8389\n",
            "Epoch 80: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.8371 - val_loss: 0.1465 - val_accuracy: 0.9669\n",
            "Epoch 81/1000\n",
            "26/38 [===================>..........] - ETA: 0s - loss: 0.4392 - accuracy: 0.8404\n",
            "Epoch 81: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.8377 - val_loss: 0.1501 - val_accuracy: 0.9651\n",
            "Epoch 82/1000\n",
            "29/38 [=====================>........] - ETA: 0s - loss: 0.4172 - accuracy: 0.8499\n",
            "Epoch 82: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.8481 - val_loss: 0.1482 - val_accuracy: 0.9682\n",
            "Epoch 83/1000\n",
            "27/38 [====================>.........] - ETA: 0s - loss: 0.4252 - accuracy: 0.8417\n",
            "Epoch 83: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.8417 - val_loss: 0.1504 - val_accuracy: 0.9663\n",
            "Epoch 84/1000\n",
            "16/38 [===========>..................] - ETA: 0s - loss: 0.4314 - accuracy: 0.8340\n",
            "Epoch 84: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.8390 - val_loss: 0.1446 - val_accuracy: 0.9688\n",
            "Epoch 85/1000\n",
            "29/38 [=====================>........] - ETA: 0s - loss: 0.4226 - accuracy: 0.8510\n",
            "Epoch 85: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.8486 - val_loss: 0.1483 - val_accuracy: 0.9644\n",
            "Epoch 86/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.4202 - accuracy: 0.8401\n",
            "Epoch 86: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.4153 - accuracy: 0.8421 - val_loss: 0.1472 - val_accuracy: 0.9669\n",
            "Epoch 87/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.4195 - accuracy: 0.8672\n",
            "Epoch 87: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3971 - accuracy: 0.8533 - val_loss: 0.1435 - val_accuracy: 0.9682\n",
            "Epoch 88/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.4139 - accuracy: 0.8459\n",
            "Epoch 88: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.8444 - val_loss: 0.1418 - val_accuracy: 0.9682\n",
            "Epoch 89/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.4209 - accuracy: 0.8423\n",
            "Epoch 89: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.8417 - val_loss: 0.1426 - val_accuracy: 0.9701\n",
            "Epoch 90/1000\n",
            "27/38 [====================>.........] - ETA: 0s - loss: 0.4117 - accuracy: 0.8501\n",
            "Epoch 90: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.8506 - val_loss: 0.1420 - val_accuracy: 0.9701\n",
            "Epoch 91/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.4582 - accuracy: 0.8281\n",
            "Epoch 91: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.8396 - val_loss: 0.1464 - val_accuracy: 0.9663\n",
            "Epoch 92/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.3785 - accuracy: 0.8828\n",
            "Epoch 92: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.8515 - val_loss: 0.1450 - val_accuracy: 0.9688\n",
            "Epoch 93/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.5702 - accuracy: 0.8281\n",
            "Epoch 93: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8508 - val_loss: 0.1393 - val_accuracy: 0.9688\n",
            "Epoch 94/1000\n",
            "25/38 [==================>...........] - ETA: 0s - loss: 0.4402 - accuracy: 0.8378\n",
            "Epoch 94: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4179 - accuracy: 0.8446 - val_loss: 0.1372 - val_accuracy: 0.9707\n",
            "Epoch 95/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.4735 - accuracy: 0.8516\n",
            "Epoch 95: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8461 - val_loss: 0.1406 - val_accuracy: 0.9688\n",
            "Epoch 96/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.4169 - accuracy: 0.8427\n",
            "Epoch 96: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.8427 - val_loss: 0.1393 - val_accuracy: 0.9719\n",
            "Epoch 97/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.4144 - accuracy: 0.8487\n",
            "Epoch 97: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.4147 - accuracy: 0.8479 - val_loss: 0.1343 - val_accuracy: 0.9713\n",
            "Epoch 98/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.4099 - accuracy: 0.8505\n",
            "Epoch 98: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.4109 - accuracy: 0.8504 - val_loss: 0.1328 - val_accuracy: 0.9732\n",
            "Epoch 99/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.4044 - accuracy: 0.8479\n",
            "Epoch 99: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.4050 - accuracy: 0.8492 - val_loss: 0.1308 - val_accuracy: 0.9738\n",
            "Epoch 100/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4131 - accuracy: 0.8467\n",
            "Epoch 100: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.4129 - accuracy: 0.8471 - val_loss: 0.1379 - val_accuracy: 0.9719\n",
            "Epoch 101/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.4101 - accuracy: 0.8478\n",
            "Epoch 101: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.8471 - val_loss: 0.1367 - val_accuracy: 0.9707\n",
            "Epoch 102/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.4124 - accuracy: 0.8527\n",
            "Epoch 102: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8533 - val_loss: 0.1365 - val_accuracy: 0.9726\n",
            "Epoch 103/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.4020 - accuracy: 0.8535\n",
            "Epoch 103: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.4020 - accuracy: 0.8535 - val_loss: 0.1308 - val_accuracy: 0.9694\n",
            "Epoch 104/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4012 - accuracy: 0.8524\n",
            "Epoch 104: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.4022 - accuracy: 0.8519 - val_loss: 0.1320 - val_accuracy: 0.9726\n",
            "Epoch 105/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.3986 - accuracy: 0.8554\n",
            "Epoch 105: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3982 - accuracy: 0.8552 - val_loss: 0.1295 - val_accuracy: 0.9726\n",
            "Epoch 106/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3972 - accuracy: 0.8533\n",
            "Epoch 106: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3972 - accuracy: 0.8533 - val_loss: 0.1251 - val_accuracy: 0.9744\n",
            "Epoch 107/1000\n",
            "25/38 [==================>...........] - ETA: 0s - loss: 0.4250 - accuracy: 0.8484\n",
            "Epoch 107: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.4080 - accuracy: 0.8523 - val_loss: 0.1302 - val_accuracy: 0.9719\n",
            "Epoch 108/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4077 - accuracy: 0.8503\n",
            "Epoch 108: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.4055 - accuracy: 0.8515 - val_loss: 0.1315 - val_accuracy: 0.9688\n",
            "Epoch 109/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3729 - accuracy: 0.8624\n",
            "Epoch 109: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3731 - accuracy: 0.8625 - val_loss: 0.1279 - val_accuracy: 0.9744\n",
            "Epoch 110/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3915 - accuracy: 0.8583\n",
            "Epoch 110: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3921 - accuracy: 0.8577 - val_loss: 0.1292 - val_accuracy: 0.9713\n",
            "Epoch 111/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3912 - accuracy: 0.8544\n",
            "Epoch 111: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3942 - accuracy: 0.8540 - val_loss: 0.1281 - val_accuracy: 0.9707\n",
            "Epoch 112/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8649\n",
            "Epoch 112: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3829 - accuracy: 0.8654 - val_loss: 0.1271 - val_accuracy: 0.9701\n",
            "Epoch 113/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3870 - accuracy: 0.8628\n",
            "Epoch 113: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3862 - accuracy: 0.8627 - val_loss: 0.1282 - val_accuracy: 0.9701\n",
            "Epoch 114/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.4054 - accuracy: 0.8483\n",
            "Epoch 114: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.8465 - val_loss: 0.1302 - val_accuracy: 0.9694\n",
            "Epoch 115/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.3783 - accuracy: 0.8516\n",
            "Epoch 115: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.3970 - accuracy: 0.8515 - val_loss: 0.1302 - val_accuracy: 0.9694\n",
            "Epoch 116/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3877 - accuracy: 0.8611\n",
            "Epoch 116: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3866 - accuracy: 0.8610 - val_loss: 0.1291 - val_accuracy: 0.9732\n",
            "Epoch 117/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3995 - accuracy: 0.8527\n",
            "Epoch 117: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3995 - accuracy: 0.8527 - val_loss: 0.1295 - val_accuracy: 0.9713\n",
            "Epoch 118/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3943 - accuracy: 0.8539\n",
            "Epoch 118: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3918 - accuracy: 0.8554 - val_loss: 0.1330 - val_accuracy: 0.9713\n",
            "Epoch 119/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4181 - accuracy: 0.8431\n",
            "Epoch 119: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.8444 - val_loss: 0.1277 - val_accuracy: 0.9719\n",
            "Epoch 120/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.3856 - accuracy: 0.8582\n",
            "Epoch 120: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3841 - accuracy: 0.8600 - val_loss: 0.1266 - val_accuracy: 0.9732\n",
            "Epoch 121/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3957 - accuracy: 0.8602\n",
            "Epoch 121: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3957 - accuracy: 0.8602 - val_loss: 0.1287 - val_accuracy: 0.9713\n",
            "Epoch 122/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.4035 - accuracy: 0.8505\n",
            "Epoch 122: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.4017 - accuracy: 0.8500 - val_loss: 0.1330 - val_accuracy: 0.9738\n",
            "Epoch 123/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.4033 - accuracy: 0.8496\n",
            "Epoch 123: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3994 - accuracy: 0.8506 - val_loss: 0.1272 - val_accuracy: 0.9701\n",
            "Epoch 124/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3985 - accuracy: 0.8511\n",
            "Epoch 124: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3959 - accuracy: 0.8523 - val_loss: 0.1217 - val_accuracy: 0.9732\n",
            "Epoch 125/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3771 - accuracy: 0.8628\n",
            "Epoch 125: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3804 - accuracy: 0.8615 - val_loss: 0.1208 - val_accuracy: 0.9738\n",
            "Epoch 126/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3829 - accuracy: 0.8589\n",
            "Epoch 126: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3812 - accuracy: 0.8600 - val_loss: 0.1202 - val_accuracy: 0.9738\n",
            "Epoch 127/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3912 - accuracy: 0.8514\n",
            "Epoch 127: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3947 - accuracy: 0.8502 - val_loss: 0.1193 - val_accuracy: 0.9713\n",
            "Epoch 128/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.4019 - accuracy: 0.8465\n",
            "Epoch 128: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.4020 - accuracy: 0.8465 - val_loss: 0.1264 - val_accuracy: 0.9676\n",
            "Epoch 129/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3800 - accuracy: 0.8579\n",
            "Epoch 129: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3781 - accuracy: 0.8592 - val_loss: 0.1233 - val_accuracy: 0.9719\n",
            "Epoch 130/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.3880 - accuracy: 0.8605\n",
            "Epoch 130: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3892 - accuracy: 0.8610 - val_loss: 0.1204 - val_accuracy: 0.9744\n",
            "Epoch 131/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3724 - accuracy: 0.8642\n",
            "Epoch 131: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3724 - accuracy: 0.8642 - val_loss: 0.1227 - val_accuracy: 0.9726\n",
            "Epoch 132/1000\n",
            "25/38 [==================>...........] - ETA: 0s - loss: 0.3804 - accuracy: 0.8672\n",
            "Epoch 132: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3824 - accuracy: 0.8644 - val_loss: 0.1185 - val_accuracy: 0.9726\n",
            "Epoch 133/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3960 - accuracy: 0.8577\n",
            "Epoch 133: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3961 - accuracy: 0.8575 - val_loss: 0.1206 - val_accuracy: 0.9744\n",
            "Epoch 134/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8636\n",
            "Epoch 134: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3799 - accuracy: 0.8635 - val_loss: 0.1190 - val_accuracy: 0.9744\n",
            "Epoch 135/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3834 - accuracy: 0.8587\n",
            "Epoch 135: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3834 - accuracy: 0.8587 - val_loss: 0.1245 - val_accuracy: 0.9726\n",
            "Epoch 136/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3775 - accuracy: 0.8608\n",
            "Epoch 136: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3775 - accuracy: 0.8608 - val_loss: 0.1197 - val_accuracy: 0.9744\n",
            "Epoch 137/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3921 - accuracy: 0.8618\n",
            "Epoch 137: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3909 - accuracy: 0.8627 - val_loss: 0.1198 - val_accuracy: 0.9732\n",
            "Epoch 138/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3919 - accuracy: 0.8566\n",
            "Epoch 138: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3944 - accuracy: 0.8565 - val_loss: 0.1201 - val_accuracy: 0.9732\n",
            "Epoch 139/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3824 - accuracy: 0.8585\n",
            "Epoch 139: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3824 - accuracy: 0.8585 - val_loss: 0.1202 - val_accuracy: 0.9738\n",
            "Epoch 140/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3926 - accuracy: 0.8548\n",
            "Epoch 140: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3895 - accuracy: 0.8558 - val_loss: 0.1222 - val_accuracy: 0.9719\n",
            "Epoch 141/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3675 - accuracy: 0.8666\n",
            "Epoch 141: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3662 - accuracy: 0.8675 - val_loss: 0.1216 - val_accuracy: 0.9713\n",
            "Epoch 142/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3906 - accuracy: 0.8547\n",
            "Epoch 142: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3891 - accuracy: 0.8552 - val_loss: 0.1216 - val_accuracy: 0.9707\n",
            "Epoch 143/1000\n",
            "27/38 [====================>.........] - ETA: 0s - loss: 0.3761 - accuracy: 0.8614\n",
            "Epoch 143: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3731 - accuracy: 0.8625 - val_loss: 0.1193 - val_accuracy: 0.9713\n",
            "Epoch 144/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3690 - accuracy: 0.8670\n",
            "Epoch 144: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3662 - accuracy: 0.8681 - val_loss: 0.1162 - val_accuracy: 0.9732\n",
            "Epoch 145/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3838 - accuracy: 0.8585\n",
            "Epoch 145: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3824 - accuracy: 0.8585 - val_loss: 0.1126 - val_accuracy: 0.9738\n",
            "Epoch 146/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3764 - accuracy: 0.8596\n",
            "Epoch 146: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3756 - accuracy: 0.8596 - val_loss: 0.1152 - val_accuracy: 0.9719\n",
            "Epoch 147/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3689 - accuracy: 0.8624\n",
            "Epoch 147: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3695 - accuracy: 0.8619 - val_loss: 0.1152 - val_accuracy: 0.9744\n",
            "Epoch 148/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.3878 - accuracy: 0.8551\n",
            "Epoch 148: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3848 - accuracy: 0.8558 - val_loss: 0.1125 - val_accuracy: 0.9769\n",
            "Epoch 149/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3686 - accuracy: 0.8640\n",
            "Epoch 149: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3681 - accuracy: 0.8642 - val_loss: 0.1122 - val_accuracy: 0.9750\n",
            "Epoch 150/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.3925 - accuracy: 0.8545\n",
            "Epoch 150: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3917 - accuracy: 0.8542 - val_loss: 0.1186 - val_accuracy: 0.9694\n",
            "Epoch 151/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3702 - accuracy: 0.8626\n",
            "Epoch 151: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3711 - accuracy: 0.8617 - val_loss: 0.1134 - val_accuracy: 0.9757\n",
            "Epoch 152/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3779 - accuracy: 0.8630\n",
            "Epoch 152: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3780 - accuracy: 0.8627 - val_loss: 0.1139 - val_accuracy: 0.9738\n",
            "Epoch 153/1000\n",
            "25/38 [==================>...........] - ETA: 0s - loss: 0.3835 - accuracy: 0.8550\n",
            "Epoch 153: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3749 - accuracy: 0.8594 - val_loss: 0.1146 - val_accuracy: 0.9750\n",
            "Epoch 154/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.4484 - accuracy: 0.8438\n",
            "Epoch 154: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3852 - accuracy: 0.8594 - val_loss: 0.1175 - val_accuracy: 0.9750\n",
            "Epoch 155/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3878 - accuracy: 0.8600\n",
            "Epoch 155: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3878 - accuracy: 0.8600 - val_loss: 0.1136 - val_accuracy: 0.9738\n",
            "Epoch 156/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3730 - accuracy: 0.8644\n",
            "Epoch 156: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3735 - accuracy: 0.8642 - val_loss: 0.1181 - val_accuracy: 0.9713\n",
            "Epoch 157/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.3719 - accuracy: 0.8658\n",
            "Epoch 157: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3700 - accuracy: 0.8660 - val_loss: 0.1139 - val_accuracy: 0.9738\n",
            "Epoch 158/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3525 - accuracy: 0.8707\n",
            "Epoch 158: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3506 - accuracy: 0.8712 - val_loss: 0.1076 - val_accuracy: 0.9757\n",
            "Epoch 159/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.3640 - accuracy: 0.8605\n",
            "Epoch 159: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3679 - accuracy: 0.8592 - val_loss: 0.1089 - val_accuracy: 0.9769\n",
            "Epoch 160/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3694 - accuracy: 0.8619\n",
            "Epoch 160: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3700 - accuracy: 0.8621 - val_loss: 0.1126 - val_accuracy: 0.9732\n",
            "Epoch 161/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.3829 - accuracy: 0.8550\n",
            "Epoch 161: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3777 - accuracy: 0.8567 - val_loss: 0.1146 - val_accuracy: 0.9750\n",
            "Epoch 162/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3614 - accuracy: 0.8676\n",
            "Epoch 162: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3610 - accuracy: 0.8677 - val_loss: 0.1104 - val_accuracy: 0.9750\n",
            "Epoch 163/1000\n",
            "25/38 [==================>...........] - ETA: 0s - loss: 0.3671 - accuracy: 0.8647\n",
            "Epoch 163: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3655 - accuracy: 0.8673 - val_loss: 0.1138 - val_accuracy: 0.9732\n",
            "Epoch 164/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.2821 - accuracy: 0.9141\n",
            "Epoch 164: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3596 - accuracy: 0.8700 - val_loss: 0.1101 - val_accuracy: 0.9713\n",
            "Epoch 165/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3724 - accuracy: 0.8653\n",
            "Epoch 165: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3734 - accuracy: 0.8652 - val_loss: 0.1099 - val_accuracy: 0.9726\n",
            "Epoch 166/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.3726 - accuracy: 0.8637\n",
            "Epoch 166: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3686 - accuracy: 0.8664 - val_loss: 0.1113 - val_accuracy: 0.9744\n",
            "Epoch 167/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3681 - accuracy: 0.8696\n",
            "Epoch 167: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3688 - accuracy: 0.8687 - val_loss: 0.1071 - val_accuracy: 0.9750\n",
            "Epoch 168/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8539\n",
            "Epoch 168: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3834 - accuracy: 0.8550 - val_loss: 0.1100 - val_accuracy: 0.9744\n",
            "Epoch 169/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3689 - accuracy: 0.8630\n",
            "Epoch 169: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3686 - accuracy: 0.8625 - val_loss: 0.1137 - val_accuracy: 0.9732\n",
            "Epoch 170/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3592 - accuracy: 0.8710\n",
            "Epoch 170: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3600 - accuracy: 0.8708 - val_loss: 0.1100 - val_accuracy: 0.9744\n",
            "Epoch 171/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.3673 - accuracy: 0.8701\n",
            "Epoch 171: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3665 - accuracy: 0.8691 - val_loss: 0.1091 - val_accuracy: 0.9713\n",
            "Epoch 172/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.3666 - accuracy: 0.8684\n",
            "Epoch 172: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3592 - accuracy: 0.8719 - val_loss: 0.1051 - val_accuracy: 0.9769\n",
            "Epoch 173/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.3741 - accuracy: 0.8693\n",
            "Epoch 173: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3736 - accuracy: 0.8685 - val_loss: 0.1063 - val_accuracy: 0.9726\n",
            "Epoch 174/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.3682 - accuracy: 0.8644\n",
            "Epoch 174: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3702 - accuracy: 0.8639 - val_loss: 0.1112 - val_accuracy: 0.9732\n",
            "Epoch 175/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3592 - accuracy: 0.8716\n",
            "Epoch 175: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3589 - accuracy: 0.8721 - val_loss: 0.1113 - val_accuracy: 0.9738\n",
            "Epoch 176/1000\n",
            "29/38 [=====================>........] - ETA: 0s - loss: 0.3645 - accuracy: 0.8734\n",
            "Epoch 176: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3672 - accuracy: 0.8704 - val_loss: 0.1077 - val_accuracy: 0.9769\n",
            "Epoch 177/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.3685 - accuracy: 0.8632\n",
            "Epoch 177: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3743 - accuracy: 0.8604 - val_loss: 0.1084 - val_accuracy: 0.9757\n",
            "Epoch 178/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3755 - accuracy: 0.8637\n",
            "Epoch 178: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3761 - accuracy: 0.8642 - val_loss: 0.1110 - val_accuracy: 0.9732\n",
            "Epoch 179/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3509 - accuracy: 0.8704\n",
            "Epoch 179: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3525 - accuracy: 0.8706 - val_loss: 0.1080 - val_accuracy: 0.9757\n",
            "Epoch 180/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3670 - accuracy: 0.8596\n",
            "Epoch 180: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3674 - accuracy: 0.8592 - val_loss: 0.1046 - val_accuracy: 0.9750\n",
            "Epoch 181/1000\n",
            "28/38 [=====================>........] - ETA: 0s - loss: 0.3732 - accuracy: 0.8594\n",
            "Epoch 181: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3745 - accuracy: 0.8592 - val_loss: 0.1110 - val_accuracy: 0.9719\n",
            "Epoch 182/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3775 - accuracy: 0.8609\n",
            "Epoch 182: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3794 - accuracy: 0.8604 - val_loss: 0.1097 - val_accuracy: 0.9732\n",
            "Epoch 183/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.3883 - accuracy: 0.8556\n",
            "Epoch 183: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3839 - accuracy: 0.8577 - val_loss: 0.1133 - val_accuracy: 0.9757\n",
            "Epoch 184/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.3787 - accuracy: 0.8558\n",
            "Epoch 184: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3760 - accuracy: 0.8571 - val_loss: 0.1119 - val_accuracy: 0.9732\n",
            "Epoch 185/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.3631 - accuracy: 0.8645\n",
            "Epoch 185: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3604 - accuracy: 0.8667 - val_loss: 0.1044 - val_accuracy: 0.9763\n",
            "Epoch 186/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.3767 - accuracy: 0.8542\n",
            "Epoch 186: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3778 - accuracy: 0.8540 - val_loss: 0.1115 - val_accuracy: 0.9738\n",
            "Epoch 187/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3567 - accuracy: 0.8713\n",
            "Epoch 187: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3597 - accuracy: 0.8696 - val_loss: 0.1080 - val_accuracy: 0.9738\n",
            "Epoch 188/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.3769 - accuracy: 0.8605\n",
            "Epoch 188: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3732 - accuracy: 0.8625 - val_loss: 0.1032 - val_accuracy: 0.9775\n",
            "Epoch 189/1000\n",
            "24/38 [=================>............] - ETA: 0s - loss: 0.3527 - accuracy: 0.8717\n",
            "Epoch 189: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3428 - accuracy: 0.8760 - val_loss: 0.1028 - val_accuracy: 0.9738\n",
            "Epoch 190/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.2351 - accuracy: 0.9219\n",
            "Epoch 190: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3650 - accuracy: 0.8689 - val_loss: 0.1037 - val_accuracy: 0.9769\n",
            "Epoch 191/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3651 - accuracy: 0.8607\n",
            "Epoch 191: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3666 - accuracy: 0.8612 - val_loss: 0.1084 - val_accuracy: 0.9738\n",
            "Epoch 192/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3610 - accuracy: 0.8702\n",
            "Epoch 192: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3633 - accuracy: 0.8698 - val_loss: 0.1059 - val_accuracy: 0.9757\n",
            "Epoch 193/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.3459 - accuracy: 0.8781\n",
            "Epoch 193: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3493 - accuracy: 0.8760 - val_loss: 0.1030 - val_accuracy: 0.9757\n",
            "Epoch 194/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.3564 - accuracy: 0.8781\n",
            "Epoch 194: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3565 - accuracy: 0.8766 - val_loss: 0.1024 - val_accuracy: 0.9769\n",
            "Epoch 195/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.3699 - accuracy: 0.8683\n",
            "Epoch 195: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3726 - accuracy: 0.8671 - val_loss: 0.1085 - val_accuracy: 0.9732\n",
            "Epoch 196/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.3708 - accuracy: 0.8632\n",
            "Epoch 196: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3720 - accuracy: 0.8619 - val_loss: 0.1058 - val_accuracy: 0.9750\n",
            "Epoch 197/1000\n",
            "25/38 [==================>...........] - ETA: 0s - loss: 0.3496 - accuracy: 0.8728\n",
            "Epoch 197: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3550 - accuracy: 0.8698 - val_loss: 0.1028 - val_accuracy: 0.9750\n",
            "Epoch 198/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.3520 - accuracy: 0.8748\n",
            "Epoch 198: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3577 - accuracy: 0.8733 - val_loss: 0.1025 - val_accuracy: 0.9763\n",
            "Epoch 199/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.3616 - accuracy: 0.8706\n",
            "Epoch 199: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3620 - accuracy: 0.8694 - val_loss: 0.1048 - val_accuracy: 0.9769\n",
            "Epoch 200/1000\n",
            "24/38 [=================>............] - ETA: 0s - loss: 0.3660 - accuracy: 0.8636\n",
            "Epoch 200: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3619 - accuracy: 0.8625 - val_loss: 0.1098 - val_accuracy: 0.9738\n",
            "Epoch 201/1000\n",
            "38/38 [==============================] - ETA: 0s - loss: 0.3607 - accuracy: 0.8725\n",
            "Epoch 201: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3607 - accuracy: 0.8725 - val_loss: 0.1083 - val_accuracy: 0.9744\n",
            "Epoch 202/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.3854 - accuracy: 0.8633\n",
            "Epoch 202: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3834 - accuracy: 0.8658 - val_loss: 0.1105 - val_accuracy: 0.9744\n",
            "Epoch 203/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3539 - accuracy: 0.8704\n",
            "Epoch 203: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3536 - accuracy: 0.8710 - val_loss: 0.1043 - val_accuracy: 0.9744\n",
            "Epoch 204/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.3723 - accuracy: 0.8676\n",
            "Epoch 204: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3703 - accuracy: 0.8664 - val_loss: 0.1051 - val_accuracy: 0.9757\n",
            "Epoch 205/1000\n",
            "26/38 [===================>..........] - ETA: 0s - loss: 0.3719 - accuracy: 0.8567\n",
            "Epoch 205: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3611 - accuracy: 0.8612 - val_loss: 0.1095 - val_accuracy: 0.9738\n",
            "Epoch 206/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3619 - accuracy: 0.8672\n",
            "Epoch 206: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3614 - accuracy: 0.8677 - val_loss: 0.1063 - val_accuracy: 0.9732\n",
            "Epoch 207/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.3550 - accuracy: 0.8653\n",
            "Epoch 207: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3582 - accuracy: 0.8625 - val_loss: 0.1074 - val_accuracy: 0.9775\n",
            "Epoch 208/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.3570 - accuracy: 0.8690\n",
            "Epoch 208: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3603 - accuracy: 0.8673 - val_loss: 0.1041 - val_accuracy: 0.9744\n",
            "Epoch 209/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.3456 - accuracy: 0.8734\n",
            "Epoch 209: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3442 - accuracy: 0.8737 - val_loss: 0.1091 - val_accuracy: 0.9744\n",
            "Epoch 210/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3725 - accuracy: 0.8661\n",
            "Epoch 210: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3722 - accuracy: 0.8656 - val_loss: 0.1086 - val_accuracy: 0.9726\n",
            "Epoch 211/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3621 - accuracy: 0.8674\n",
            "Epoch 211: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3620 - accuracy: 0.8677 - val_loss: 0.1016 - val_accuracy: 0.9750\n",
            "Epoch 212/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.3482 - accuracy: 0.8658\n",
            "Epoch 212: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3467 - accuracy: 0.8658 - val_loss: 0.1064 - val_accuracy: 0.9738\n",
            "Epoch 213/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3564 - accuracy: 0.8748\n",
            "Epoch 213: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3565 - accuracy: 0.8739 - val_loss: 0.1049 - val_accuracy: 0.9750\n",
            "Epoch 214/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3665 - accuracy: 0.8668\n",
            "Epoch 214: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3640 - accuracy: 0.8673 - val_loss: 0.1079 - val_accuracy: 0.9726\n",
            "Epoch 215/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.3472 - accuracy: 0.8775\n",
            "Epoch 215: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3449 - accuracy: 0.8787 - val_loss: 0.1013 - val_accuracy: 0.9750\n",
            "Epoch 216/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3401 - accuracy: 0.8770\n",
            "Epoch 216: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3392 - accuracy: 0.8762 - val_loss: 0.1031 - val_accuracy: 0.9738\n",
            "Epoch 217/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3812 - accuracy: 0.8611\n",
            "Epoch 217: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3826 - accuracy: 0.8606 - val_loss: 0.1059 - val_accuracy: 0.9763\n",
            "Epoch 218/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.3623 - accuracy: 0.8752\n",
            "Epoch 218: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3568 - accuracy: 0.8762 - val_loss: 0.1061 - val_accuracy: 0.9763\n",
            "Epoch 219/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.3728 - accuracy: 0.8612\n",
            "Epoch 219: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3706 - accuracy: 0.8606 - val_loss: 0.1109 - val_accuracy: 0.9750\n",
            "Epoch 220/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3537 - accuracy: 0.8750\n",
            "Epoch 220: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3516 - accuracy: 0.8758 - val_loss: 0.1115 - val_accuracy: 0.9738\n",
            "Epoch 221/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3580 - accuracy: 0.8730\n",
            "Epoch 221: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3587 - accuracy: 0.8719 - val_loss: 0.1108 - val_accuracy: 0.9726\n",
            "Epoch 222/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.3625 - accuracy: 0.8663\n",
            "Epoch 222: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3599 - accuracy: 0.8671 - val_loss: 0.1075 - val_accuracy: 0.9757\n",
            "Epoch 223/1000\n",
            "28/38 [=====================>........] - ETA: 0s - loss: 0.3514 - accuracy: 0.8797\n",
            "Epoch 223: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3535 - accuracy: 0.8762 - val_loss: 0.1033 - val_accuracy: 0.9757\n",
            "Epoch 224/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.3703 - accuracy: 0.8681\n",
            "Epoch 224: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3675 - accuracy: 0.8683 - val_loss: 0.1085 - val_accuracy: 0.9763\n",
            "Epoch 225/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3619 - accuracy: 0.8678\n",
            "Epoch 225: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3638 - accuracy: 0.8677 - val_loss: 0.1121 - val_accuracy: 0.9719\n",
            "Epoch 226/1000\n",
            "23/38 [=================>............] - ETA: 0s - loss: 0.3503 - accuracy: 0.8702\n",
            "Epoch 226: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3447 - accuracy: 0.8710 - val_loss: 0.1057 - val_accuracy: 0.9763\n",
            "Epoch 227/1000\n",
            "31/38 [=======================>......] - ETA: 0s - loss: 0.3639 - accuracy: 0.8644\n",
            "Epoch 227: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3556 - accuracy: 0.8660 - val_loss: 0.1064 - val_accuracy: 0.9738\n",
            "Epoch 228/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.3584 - accuracy: 0.8676\n",
            "Epoch 228: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3583 - accuracy: 0.8677 - val_loss: 0.1088 - val_accuracy: 0.9719\n",
            "Epoch 229/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3533 - accuracy: 0.8695\n",
            "Epoch 229: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3536 - accuracy: 0.8691 - val_loss: 0.1053 - val_accuracy: 0.9757\n",
            "Epoch 230/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.4117 - accuracy: 0.8750\n",
            "Epoch 230: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3603 - accuracy: 0.8716 - val_loss: 0.1065 - val_accuracy: 0.9763\n",
            "Epoch 231/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.3687 - accuracy: 0.8691\n",
            "Epoch 231: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3611 - accuracy: 0.8712 - val_loss: 0.1030 - val_accuracy: 0.9757\n",
            "Epoch 232/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.3652 - accuracy: 0.8674\n",
            "Epoch 232: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3664 - accuracy: 0.8656 - val_loss: 0.1065 - val_accuracy: 0.9738\n",
            "Epoch 233/1000\n",
            "20/38 [==============>...............] - ETA: 0s - loss: 0.3494 - accuracy: 0.8715\n",
            "Epoch 233: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3485 - accuracy: 0.8687 - val_loss: 0.1044 - val_accuracy: 0.9757\n",
            "Epoch 234/1000\n",
            " 1/38 [..............................] - ETA: 0s - loss: 0.2963 - accuracy: 0.8984\n",
            "Epoch 234: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3584 - accuracy: 0.8708 - val_loss: 0.1002 - val_accuracy: 0.9757\n",
            "Epoch 235/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3517 - accuracy: 0.8715\n",
            "Epoch 235: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3502 - accuracy: 0.8723 - val_loss: 0.1032 - val_accuracy: 0.9744\n",
            "Epoch 236/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.3458 - accuracy: 0.8752\n",
            "Epoch 236: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3497 - accuracy: 0.8725 - val_loss: 0.1033 - val_accuracy: 0.9769\n",
            "Epoch 237/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.3435 - accuracy: 0.8750\n",
            "Epoch 237: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3455 - accuracy: 0.8739 - val_loss: 0.1021 - val_accuracy: 0.9738\n",
            "Epoch 238/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.3438 - accuracy: 0.8708\n",
            "Epoch 238: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3427 - accuracy: 0.8714 - val_loss: 0.1024 - val_accuracy: 0.9775\n",
            "Epoch 239/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3451 - accuracy: 0.8752\n",
            "Epoch 239: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3471 - accuracy: 0.8741 - val_loss: 0.1009 - val_accuracy: 0.9744\n",
            "Epoch 240/1000\n",
            "22/38 [================>.............] - ETA: 0s - loss: 0.3352 - accuracy: 0.8764\n",
            "Epoch 240: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3497 - accuracy: 0.8746 - val_loss: 0.1007 - val_accuracy: 0.9757\n",
            "Epoch 241/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3716 - accuracy: 0.8607\n",
            "Epoch 241: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3731 - accuracy: 0.8606 - val_loss: 0.1017 - val_accuracy: 0.9744\n",
            "Epoch 242/1000\n",
            "30/38 [======================>.......] - ETA: 0s - loss: 0.3397 - accuracy: 0.8763\n",
            "Epoch 242: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3427 - accuracy: 0.8739 - val_loss: 0.1061 - val_accuracy: 0.9769\n",
            "Epoch 243/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3375 - accuracy: 0.8783\n",
            "Epoch 243: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3382 - accuracy: 0.8777 - val_loss: 0.1005 - val_accuracy: 0.9744\n",
            "Epoch 244/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3585 - accuracy: 0.8737\n",
            "Epoch 244: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3567 - accuracy: 0.8741 - val_loss: 0.1043 - val_accuracy: 0.9713\n",
            "Epoch 245/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.3380 - accuracy: 0.8810\n",
            "Epoch 245: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3396 - accuracy: 0.8793 - val_loss: 0.1016 - val_accuracy: 0.9800\n",
            "Epoch 246/1000\n",
            "24/38 [=================>............] - ETA: 0s - loss: 0.3596 - accuracy: 0.8721\n",
            "Epoch 246: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3504 - accuracy: 0.8739 - val_loss: 0.1034 - val_accuracy: 0.9738\n",
            "Epoch 247/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.3438 - accuracy: 0.8725\n",
            "Epoch 247: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3463 - accuracy: 0.8706 - val_loss: 0.1035 - val_accuracy: 0.9750\n",
            "Epoch 248/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.3383 - accuracy: 0.8760\n",
            "Epoch 248: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3348 - accuracy: 0.8793 - val_loss: 0.0992 - val_accuracy: 0.9757\n",
            "Epoch 249/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.3574 - accuracy: 0.8738\n",
            "Epoch 249: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3588 - accuracy: 0.8725 - val_loss: 0.1052 - val_accuracy: 0.9732\n",
            "Epoch 250/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3569 - accuracy: 0.8697\n",
            "Epoch 250: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3558 - accuracy: 0.8706 - val_loss: 0.1046 - val_accuracy: 0.9738\n",
            "Epoch 251/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.3339 - accuracy: 0.8794\n",
            "Epoch 251: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3393 - accuracy: 0.8764 - val_loss: 0.1017 - val_accuracy: 0.9750\n",
            "Epoch 252/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.3461 - accuracy: 0.8707\n",
            "Epoch 252: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3450 - accuracy: 0.8727 - val_loss: 0.1035 - val_accuracy: 0.9750\n",
            "Epoch 253/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3423 - accuracy: 0.8757\n",
            "Epoch 253: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3455 - accuracy: 0.8752 - val_loss: 0.1007 - val_accuracy: 0.9757\n",
            "Epoch 254/1000\n",
            "31/38 [=======================>......] - ETA: 0s - loss: 0.3522 - accuracy: 0.8705\n",
            "Epoch 254: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3583 - accuracy: 0.8685 - val_loss: 0.1030 - val_accuracy: 0.9732\n",
            "Epoch 255/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.3442 - accuracy: 0.8757\n",
            "Epoch 255: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3435 - accuracy: 0.8762 - val_loss: 0.1039 - val_accuracy: 0.9732\n",
            "Epoch 256/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3586 - accuracy: 0.8665\n",
            "Epoch 256: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3537 - accuracy: 0.8691 - val_loss: 0.0993 - val_accuracy: 0.9757\n",
            "Epoch 257/1000\n",
            "27/38 [====================>.........] - ETA: 0s - loss: 0.3389 - accuracy: 0.8773\n",
            "Epoch 257: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3362 - accuracy: 0.8779 - val_loss: 0.1006 - val_accuracy: 0.9782\n",
            "Epoch 258/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.3524 - accuracy: 0.8730\n",
            "Epoch 258: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3526 - accuracy: 0.8737 - val_loss: 0.1067 - val_accuracy: 0.9738\n",
            "Epoch 259/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.3394 - accuracy: 0.8764\n",
            "Epoch 259: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3354 - accuracy: 0.8789 - val_loss: 0.0998 - val_accuracy: 0.9775\n",
            "Epoch 260/1000\n",
            "32/38 [========================>.....] - ETA: 0s - loss: 0.3478 - accuracy: 0.8774\n",
            "Epoch 260: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3468 - accuracy: 0.8796 - val_loss: 0.1006 - val_accuracy: 0.9775\n",
            "Epoch 261/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.3435 - accuracy: 0.8710\n",
            "Epoch 261: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3397 - accuracy: 0.8727 - val_loss: 0.0966 - val_accuracy: 0.9800\n",
            "Epoch 262/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.3565 - accuracy: 0.8712\n",
            "Epoch 262: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3559 - accuracy: 0.8714 - val_loss: 0.1033 - val_accuracy: 0.9769\n",
            "Epoch 263/1000\n",
            "23/38 [=================>............] - ETA: 0s - loss: 0.3511 - accuracy: 0.8753\n",
            "Epoch 263: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3512 - accuracy: 0.8739 - val_loss: 0.1040 - val_accuracy: 0.9744\n",
            "Epoch 264/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3311 - accuracy: 0.8792\n",
            "Epoch 264: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3320 - accuracy: 0.8785 - val_loss: 0.1025 - val_accuracy: 0.9726\n",
            "Epoch 265/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.3419 - accuracy: 0.8717\n",
            "Epoch 265: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3421 - accuracy: 0.8714 - val_loss: 0.1004 - val_accuracy: 0.9744\n",
            "Epoch 266/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.3350 - accuracy: 0.8774\n",
            "Epoch 266: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3380 - accuracy: 0.8733 - val_loss: 0.1014 - val_accuracy: 0.9732\n",
            "Epoch 267/1000\n",
            "37/38 [============================>.] - ETA: 0s - loss: 0.3470 - accuracy: 0.8742\n",
            "Epoch 267: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3493 - accuracy: 0.8737 - val_loss: 0.1032 - val_accuracy: 0.9732\n",
            "Epoch 268/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.3439 - accuracy: 0.8789\n",
            "Epoch 268: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3477 - accuracy: 0.8777 - val_loss: 0.1035 - val_accuracy: 0.9732\n",
            "Epoch 269/1000\n",
            "27/38 [====================>.........] - ETA: 0s - loss: 0.3524 - accuracy: 0.8698\n",
            "Epoch 269: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3440 - accuracy: 0.8731 - val_loss: 0.1023 - val_accuracy: 0.9782\n",
            "Epoch 270/1000\n",
            "31/38 [=======================>......] - ETA: 0s - loss: 0.3353 - accuracy: 0.8760\n",
            "Epoch 270: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3399 - accuracy: 0.8746 - val_loss: 0.1010 - val_accuracy: 0.9794\n",
            "Epoch 271/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.3402 - accuracy: 0.8759\n",
            "Epoch 271: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3431 - accuracy: 0.8737 - val_loss: 0.1045 - val_accuracy: 0.9744\n",
            "Epoch 272/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.3420 - accuracy: 0.8738\n",
            "Epoch 272: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3434 - accuracy: 0.8725 - val_loss: 0.1032 - val_accuracy: 0.9738\n",
            "Epoch 273/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.3367 - accuracy: 0.8759\n",
            "Epoch 273: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3375 - accuracy: 0.8746 - val_loss: 0.1041 - val_accuracy: 0.9750\n",
            "Epoch 274/1000\n",
            "24/38 [=================>............] - ETA: 0s - loss: 0.3414 - accuracy: 0.8750\n",
            "Epoch 274: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3480 - accuracy: 0.8733 - val_loss: 0.1011 - val_accuracy: 0.9763\n",
            "Epoch 275/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.3366 - accuracy: 0.8770\n",
            "Epoch 275: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3362 - accuracy: 0.8775 - val_loss: 0.0999 - val_accuracy: 0.9775\n",
            "Epoch 276/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.3368 - accuracy: 0.8795\n",
            "Epoch 276: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3369 - accuracy: 0.8800 - val_loss: 0.1007 - val_accuracy: 0.9769\n",
            "Epoch 277/1000\n",
            "33/38 [=========================>....] - ETA: 0s - loss: 0.3485 - accuracy: 0.8667\n",
            "Epoch 277: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3456 - accuracy: 0.8671 - val_loss: 0.1029 - val_accuracy: 0.9757\n",
            "Epoch 278/1000\n",
            "36/38 [===========================>..] - ETA: 0s - loss: 0.3338 - accuracy: 0.8761\n",
            "Epoch 278: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3337 - accuracy: 0.8760 - val_loss: 0.1056 - val_accuracy: 0.9738\n",
            "Epoch 279/1000\n",
            "31/38 [=======================>......] - ETA: 0s - loss: 0.3500 - accuracy: 0.8674\n",
            "Epoch 279: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.3512 - accuracy: 0.8708 - val_loss: 0.1033 - val_accuracy: 0.9782\n",
            "Epoch 280/1000\n",
            "34/38 [=========================>....] - ETA: 0s - loss: 0.3436 - accuracy: 0.8794\n",
            "Epoch 280: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3445 - accuracy: 0.8781 - val_loss: 0.1056 - val_accuracy: 0.9769\n",
            "Epoch 281/1000\n",
            "35/38 [==========================>...] - ETA: 0s - loss: 0.3557 - accuracy: 0.8701\n",
            "Epoch 281: saving model to /home/yunusdanabas/catkin_ws/src/ros_hand_gesture_recognition/src/model/keypoint_classifier/keypoint_classifier.hdf5\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.3539 - accuracy: 0.8694 - val_loss: 0.1077 - val_accuracy: 0.9732\n",
            "Epoch 281: early stopping\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f7b3c277c10>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=1000,\n",
        "    batch_size=128,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[cp_callback, es_callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxvb2Y299hE3",
        "outputId": "59eb3185-2e37-4b9e-bc9d-ab1b8ac29b7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13/13 [==============================] - 0s 1ms/step - loss: 0.1077 - accuracy: 0.9732\n"
          ]
        }
      ],
      "source": [
        "# Model evaluation\n",
        "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RBkmDeUW9hE4"
      },
      "outputs": [],
      "source": [
        "# Loading the saved model\n",
        "model = tf.keras.models.load_model(model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFz9Tb0I9hE4",
        "outputId": "1c3b3528-54ae-4ee2-ab04-77429211cbef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 99ms/step\n",
            "[8.0789375e-04 7.2513364e-02 1.1769754e-17 4.0474491e-15 9.2667848e-01\n",
            " 1.7725883e-07]\n",
            "4\n"
          ]
        }
      ],
      "source": [
        "# Inference test\n",
        "predict_result = model.predict(np.array([X_test[0]]))\n",
        "print(np.squeeze(predict_result))\n",
        "print(np.argmax(np.squeeze(predict_result)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3U4yNWx9hE4"
      },
      "source": [
        "# Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "AP1V6SCk9hE5",
        "outputId": "08e41a80-7a4a-4619-8125-ecc371368d19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "51/51 [==============================] - 0s 746us/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99       415\n",
            "           1       0.99      0.92      0.95       395\n",
            "           2       0.97      1.00      0.98       176\n",
            "           3       0.98      1.00      0.99       261\n",
            "           4       0.92      1.00      0.96       175\n",
            "           5       0.96      0.99      0.97       181\n",
            "\n",
            "    accuracy                           0.97      1603\n",
            "   macro avg       0.97      0.98      0.97      1603\n",
            "weighted avg       0.97      0.97      0.97      1603\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def print_confusion_matrix(y_true, y_pred, report=True):\n",
        "    labels = sorted(list(set(y_true)))\n",
        "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    \n",
        "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
        " \n",
        "    fig, ax = plt.subplots(figsize=(7, 6))\n",
        "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
        "    ax.set_ylim(len(set(y_true)), 0)\n",
        "    plt.show()\n",
        "    \n",
        "    if report:\n",
        "        print('Classification Report')\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "Y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "print_confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNP6aqzc9hE5"
      },
      "source": [
        "# Convert to model for Tensorflow-Lite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ODjnYyld9hE6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/yunusdanabas/mambaforge/envs/ros_env/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# Save as a model dedicated to inference\n",
        "model.save(model_save_path, include_optimizer=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRfuK8Y59hE6",
        "outputId": "a4ca585c-b5d5-4244-8291-8674063209bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp1qemuul4/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp1qemuul4/assets\n",
            "2025-03-19 22:51:03.254054: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
            "2025-03-19 22:51:03.254096: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
            "2025-03-19 22:51:03.254615: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmp1qemuul4\n",
            "2025-03-19 22:51:03.256637: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
            "2025-03-19 22:51:03.256678: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmp1qemuul4\n",
            "2025-03-19 22:51:03.261512: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
            "2025-03-19 22:51:03.262878: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
            "2025-03-19 22:51:03.309181: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmp1qemuul4\n",
            "2025-03-19 22:51:03.322824: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 68212 microseconds.\n",
            "2025-03-19 22:51:03.343686: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "6632"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Transform model (quantization)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quantized_model = converter.convert()\n",
        "\n",
        "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHBPBXdx9hE6"
      },
      "source": [
        "# Inference test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "mGAzLocO9hE7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
          ]
        }
      ],
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
        "interpreter.allocate_tensors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "oQuDK8YS9hE7"
      },
      "outputs": [],
      "source": [
        "# Get I / O tensor\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "2_ixAf_l9hE7"
      },
      "outputs": [],
      "source": [
        "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4FoAnuc9hE7",
        "outputId": "91f18257-8d8b-4ef3-c558-e9b5f94fabbf",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 467 µs, sys: 0 ns, total: 467 µs\n",
            "Wall time: 427 µs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Inference implementation\n",
        "interpreter.invoke()\n",
        "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vONjp19J9hE8",
        "outputId": "77205e24-fd00-42c4-f7b6-e06e527c2cba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[8.0789416e-04 7.2513409e-02 1.1769800e-17 4.0474652e-15 9.2667860e-01\n",
            " 1.7725934e-07]\n",
            "4\n"
          ]
        }
      ],
      "source": [
        "print(np.squeeze(tflite_results))\n",
        "print(np.argmax(np.squeeze(tflite_results)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "keypoint_classification_EN.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "ros_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
